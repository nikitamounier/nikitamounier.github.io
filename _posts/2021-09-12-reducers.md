---
layout: post
title: Reducers, or understanding the shape of functions
---

Swift is a peculiar language in that it combines many ‚Äúparadigms‚Äù ‚Äì¬†styles of programming ‚Äì¬†to create a sort of melting pot where developers can pick and choose which style they prefer. One such paradigm that I‚Äôm very interested in is ‚Äúfunctional programming‚Äù. [Wikipedia states](https://en.wikipedia.org/wiki/Functional_programming):

> In computer science, functional programming is a programming paradigm where programs are constructed by applying and composing functions. It is a [‚Ä¶] paradigm in which function definitions [‚Ä¶] map values to other values, rather than a sequence of imperative statements which update the running state of the program.

*Applying and composing functions*. Sounds a bit abstract, doesn‚Äôt it? What does that actually mean? In this article, I want to show you concrete examples of this paradigm in Swift through *reducers*, and teach you a core skill in functional programming: understanding the shape of functions.  <!--more-->

## Functional methods in Swift

As I said before, Swift has deep roots in functional programming. This can be best seen in its standard library, where it offers higher-order functions notably on Sequences.

A first example of this is the `.map { }` method. Say we want to go from an array of `Car` to an array of `Driver`:

{{ gist f3d60dc0c51f7be6cba586086d528b53 }}

There is an important distinction between the two. In the imperative way, we are going step-by-step telling Swift exactly what mutations we want to happen when and where. Meanwhile, in the functional way, we are simply ***describing*** the transformation we want to happen, by giving the `.map { }` a closure in which we produce a new `Driver` when given a `Car`.

Even better we can make this even more succinct and descriptive by providing `Driver` with a special initializer:

{{ gist abbc4268313bdd36907cd3eccc27f9a8 }}

Now, we‚Äôre truly describing what we want to happen: we want to map each `Car` in the array into a `Driver`. As simple as that. No weird mutations, which means no space for error. 

A similar thing can be said for the `.filter { }` method. Instead of mapping over each element of a sequence, we instead include only certain elements from a sequence, based on a condition given some element. It‚Äôll be clearer when I show it to you.

Say we want to create a new `Driver` array, which only contains the adventurous drivers.

{{ gist 7856b85cef0f39fdc434b6e289d3d8bf }}

Once again, in the imperative method, we‚Äôre going line by line, conditionally appending the driver if their `isAdventurous` property is set to true. Meanwhile once again in the functional way we‚Äôre just describing the condition given a driver, freeing us from having to perform error-prone mutations ourselves. Even better, thanks to [SE-0249 - Key Path Expressions as Functions](https://github.com/apple/swift-evolution/blob/main/proposals/0249-key-path-literal-function-expressions.md), we can shorten it to this:

{{ gist f4e80bcc72094521020af2d99de21f30 }}

Clean, right? I think that you now have a good understanding on how `map` and `filter` are part of the foundational building blocks of functional programming. They are tools which offer us transformations on basic types like arrays and dictionaries. 

Going back to the Wikipedia quote, it seems like we‚Äôve become quite good at *applying* functions. So the logical next step would be *composing* functions, right?

## The Composition Dilemma

Let‚Äôs look at the signature for both `map` and `filter` on sequences:

> `func map<T>(_ transform: (Element)  -> T) -> [T]`
>
> `func filter(_ isIncluded: (Element) -> Bool) -> [Element]`

Both of the methods seem to return a new array ‚Äî `map` returns an array of some generic type `T`, and filter returns an array with elements of the same type `Element`. Since they‚Äôre both extensions on sequences, we should be able to just chain these two together.

Say we wanted to go straight from an array of cars to an array of adventurous drivers. Intuitively, we can do this:

{{ gist 38e6e050dd8bb0d4a1a364f6b86c1547 }}

Looks nice and functional, don‚Äôt you think? However, there is a hidden problem lurking in this piece of code. The issue is, these two `map` and `filter` methods have no idea about each other‚Äôs existence.  Therefore, `map` allocates a whole new array, applies its transformation, and returns the array ‚Äî and then `filter` allocates another whole new array, filters in the elements which pass the condition, and returns the second array. We‚Äôve allocated two arrays in an operation which really should only require one. 

Let me translate this exact code into imperative code so that you can see what I mean:

```swift
var driversFromCars: [Driver] = [] // array 1
for car in cars {
    driversFromCars.append(Driver(car: car))
}

var adventurousDrivers: [Driver] = [] // array 2
for driver in driversFromCars {
    if driver.isAdventurous {
        adventurousDrivers.append(driver)
    }
}
return adventurousDrivers
```

If you are familiar with the concept of [time complexity](https://en.wikipedia.org/wiki/Time_complexity), this operation is *O(n^2^)*, when it should really be *O(n)*.

‚ÄúSo what?‚Äù, I hear you say. ‚ÄúWhy should I care? Allocating two arrays with a couple of elements is no big deal.‚Äù Sure, it doesn‚Äôt make a difference with today‚Äôs hardware if you have a couple of elements each with a handful of properties.

 But once you start getting into the thousands / tens of thousands of elements, and each element has their own arrays with sequences with hundreds of elements ‚Äî that‚Äôs when you start noticing stutters and performance drops in your software. And last time I checked, nobody likes performance drops.

## Reducers to the rescue

First, a short introduction to reducers. The `reduce` function is the third foundational building block of functional programming, alongside `map` and `filter`. I like to call `reduce` the ‚ÄúSwiss army knife of functions‚Äù, because it can do just about anything ‚Äî including mapping and filtering. Confused? Let me explain.

Instead of showing the `.reduce([]) { }` method in action like I did for `map` and `filter`, I‚Äôm going to show you the ***shape*** of a reducer. By shape, I mean the relation between its parameters and return value:

```swift
typealias Reducer<A, B> = (A, B) -> A
```

As you see, a reducer takes two input parameters, of type  `A` and `B`, and then *reduces* the two into a new value of type `A`. At its core, that‚Äôs all there is to a reducer. 

So how could that possibly help us in our composition dilemma with `map` and `filter`?

Well, in the case of `map`, we could think of `A` as the new array we want to create, and `B` as an element of the old array which we shall transform. Then, the reducer will iterate on each element of the old array, updating the new array each time as we transform each element. Something like this:

```swift
let drivers: [Driver] = cars
	.reduce([]) { (newArray: [Driver], oldElement: Car) -> [Driver] in // (A, B) -> A
    	var accumulation = newArray
        accumulation.append(Driver(car: oldElement)) // this gets called on each element
        return accumulation
    }
```

This code snippet is definitely a lot to take in. Essentially, for each element in the old array, we‚Äôre *reducing* the new array and the current element, by adding the transformed element to the accumulation.

This means we can define `map` by only using a reducer:

```swift
extension Sequence {
    func reducerMap<B>(_ transform: @escaping (Element) -> B) -> [B] {
        return self.reduce([]) { accumulation, element in
            return accumulation + [transform(element)]
        }
    }
}

let drivers = cars.map(Driver.init)
let reducerDrivers = cars.reducerMap(Driver.init)

print(drivers == reducerDrivers) // true
```

Now that we‚Äôve settled that `reduce` can be used as a generalization over `map`, let‚Äôs see how the same can be said for `filter`.

Let‚Äôs remind ourselves how we defined a reducer:

```swift
typealias Reducer<A, B> = (A, B) -> A
```

Much like with `map`, we can think of `A` as the new array we want to create. However, instead of `B` being the element of the old array which will be transformed, `B` is the element of the old array which will conditionally be added to `A`.

```swift
let adventurousDrivers: [Driver] = driver
	.reduce([]) { newArray, oldElement -> [Driver] in // (A, B) -> A
        if oldElement.isAdventurous {
            return newArray + [oldElement]
        } else {
            return newArray
        }
    }
```

We‚Äôre *reducing* the new array and the current element not by adding the transformed element, but instead by only adding the element if it meets our condition. This means that we can also define `filter` by only using a reducer:

```swift
extension Sequence {
    func reducerFilter(_ isIncluded: @escaping (Element) -> Bool) -> [Element] {
        return self.reduce([]) { accumulation, element in
            if isIncluded(element) {
                return accumulation + [element]
            } else {
                return newArray
            }
        }
    }
}

let adventurousDrivers = drivers.filter(\.isAdventurous)
let reducerAdventurousDrivers = drivers.reducerFilter(\.isAdventurous)

print(adventurousDrivers == reducerAdventurousDrivers) // true
```

Now we‚Äôve demonstrated that `reduce` can also be used as a generalization over `filter`. 

Before we go any further, there‚Äôs a pattern I‚Äôve noticed in both the `reducer...` functions:

```swift
return accumulation + [element]
```

This is actually quite an essential part to our reducers, since they define *how* we want to reduce the two parameters. Let‚Äôs extract this into its own function for reusability‚Äôs sake.

```swift
func append<A, B>(to accumulation: A, element: B) -> A where A: RangeReplaceableCollection, A.Element == B {
    return accumulation + [element]
}
```

Interestingly, this function itself is a reducer ‚Äî you can clearly see the shape of `(A, B) -> A` (with just the two parameters swapped).

Back to the composition dilemma. How could we restore performance without falling back into the messy mutation-filled world of imperative programming? We could try combining the two `map` and `filter` reducers we created up above:

```swift
let adventurousDrivers = cars
	.reduce([]) { accumulation, element in
         let driver = Drive(car: element) // from map
         if driver.isAdventurous { // from filter
             return append(to: accumulation, element: driver)
         } else {
             return accumulation
         }
     }
```

Not bad! Now, thanks to the reducer, we‚Äôre back to not creating an intermediate array between the mapping and filtering. However, we have in a sense lost some composition ‚Äî we‚Äôre back to doing imperative control flow, and every time we want to add a map or filter to it we‚Äôll have to carefully place it to make sure we‚Äôre not making any logic errors. Can‚Äôt there be some way to generalize all our logic here into simple, composable functions?

## From control flow to functions

An important skill to have when doing functional programming is being able to translate imperative control flow to a composition of functions. To do this, you need to identify certain patterns, and see how you can generalise over them using functions. Let‚Äôs look at that reducer from the last code snippet:

```swift
.reduce([]) { accumulation, element in // (A, B) -> A
         let driver = Drive(car: element)
         if driver.isAdventurous {
             return append(to: accumulation, element: driver) // -> A
         } else {
             return accumulation // -> A
         }
     }
```

We can divide this code into three main sections:

1. Mapping over an element
2. Filtering in an element
3. Returning the accumulation, with the element appended to it or not.

Finally, the whole closure needs to have the shape `(A, B) -> A`. This means that whichever general functions we create need to ultimately return a function of type `(A, B) -> A`.

### 1. Map

Let‚Äôs look at the mapping over an element first. Mapping over an element here means applying a function to it which takes it from `A -> B`, and then reducing that element with the accumulation, as seen in the `reducerMap` function up above. So what do we need to create such a general `map` function? We need:

- The function which takes each element from `A -> B`
- The reducer function, which will take some accumulation and element, and return the accumulation

We return:

- A reducer function which takes the actual accumulation and elements themselves, and applies them to the reducer function which was given to us. 

**Tip**: The rest of the article will use a concept called *function currying*. Keep on reading, I‚Äôll try to explain as clearly as possible, but if still you feel really lost I highly advise you to check out [this article](https://thoughtbot.com/blog/introduction-to-function-currying-in-swift).

The thing is, we want to keep this `map` function as generic and flexible as possible, meaning that we don‚Äôt want to force the caller to have to give all three of these things at once. The caller should be able to only give the function that makes each element go from `A -> B`, and then much later give the reducer function, and then even later plug in the actual accumulation and elements. It‚Äôs keeping this flexibility in mind which enables you to create really powerful compositions of functions.

That‚Äôs where *function currying* comes in. With function currying, you can give a function a single argument, and then that function will return a whole new function which wants an argument, and so on. This allows you to be very flexible, because you can store a function with 1 out of 3 arguments filled in, or maybe store another function with 3 out of 4 arguments filled in. Let me give you an example:

```swift
func add5(_ first: Int, _ second: Int, _ third: Int, _ fourth: Int, _ fifth: Int) -> Int {
    return first + second + third + fourth + fifth
}

let n: Int = add5(1, 2, 3, 4, 5) // 15
```

This looks a nice little function, except for the fact that I‚Äôm completely stuck with it. There's nothing else I can do, other than use different arguments. Meanwhile, if I were to use function currying, a whole world of possibilities opens up:

```swift
func add5(_ first: Int) -> (Int) -> (Int) -> (Int) -> (Int) -> Int {
    return { second in
        return { third in
            return { fourth in
                return { fifth in
                     return first + second + third + fourth + fifth
                }
            }
        }
    }
}
```

This looks ugly on purpose ‚Äì I really wanted to show you how at every step we‚Äôre returning a *new* function (or closure), ultimately returning the addition once we‚Äôve gathered all the parameters. We can do the same thing as with the previous function, while instead calling the new function every time with a single parameter:

```swift
let n = add5(1)(2)(3)(4)(5) // 15
```

But we can do some more interesting things too:

```swift
let atLeast2 = add(2)
type(of: atLeast2) // (Int) -> (Int) -> (Int) -> (Int) -> Int
```

Calling `add(2)` has created a new function which takes 4 ‚Äúparameters‚Äù instead of 5. Interestingly, the result will always be at least 2 (assuming only positive integers were input), because we‚Äôve hard-coded the fact that the first parameter is always 2. We can by extension do the same thing with the second parameter:

```swift
let atLeast5 = atLeast2(3)
type(of: atLeast5) // (Int) -> (Int) -> (Int) -> Int
```

I hope you now understand the power of *function currying*, and why we‚Äôll be using it for our generic functions, such as `map`. 

Let‚Äôs remind ourselves what we need:

- The function which takes each element from `A -> B`
- The reducer function, which will take some accumulation and element, and return the accumulation

And what we return:

- A reducer function which takes the actual accumulation and elements themselves, and applies them to the reducer function which was given to us.

With this, we can start making a function signature. We‚Äôll have three types: `A`, the original type of some element; `B`, the new type of said element after being mapped; and `C`, the accumulation which we‚Äôll be reducing with the mapped element.

First off, we have the first parameter:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> ...
```

Looks simple for now. Next, we need the reducer function. Remember, reducers have the shape `(X, Y) -> X`, with `X` being the accumulation and `Y` being the element. This reducer function will obviously need to work on elements of type `B` and accumulation of type `C`, so it will have this signature:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (C, B) -> C ...
```

This seems to make sense. If you‚Äôre getting confused by the whole ‚Äúshape of reducers‚Äù concept feel free to scroll back up and re-read the ‚ÄúReducers to the rescue‚Äù section.

Finally, we return the function which‚Äôll take the actual accumulation and element. Think back to the `. reduce([]) { ..., ..., in }` method on sequences ‚Äî that closure itself, with the brackets and the two parameters, is the function which takes the actual accumulation and element. The accumulation will still be of type `C`, that still hasn‚Äôt changed. However, we still haven‚Äôt mapped over the elements yet, they‚Äôve just been given to us by that closure. This means that *the elements are still of type `A`*. So, the signature ends up looking like this:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (C, B) -> C -> (C, A) -> C
```

Pretty intense, right? It helps to read it out loud in English:

‚ÄúMap is a function which takes a function from A to B, and returns a new function. This new function takes a reducer which takes C and B and returns C, and it returns a new reducer which takes C and A and also returns C.‚Äù

Quite the mouthful, I know. But if you‚Äôre able to at least partly understand this, you‚Äôve already made massive strides in understanding the shape of functions. Enough talking, let‚Äôs implement this function. First off, the first thing we do is return a new function which takes a reducer of type `(C, B) -> C` as a parameter. Unfortunately, due to Swift‚Äôs syntax, we have to make the signature slightly uglier:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (@escaping (C, B) -> C) -> (C, A) -> C {
    return { reducer in // (C, B) -> C
        // ...
    }
}
```

Next, now that we have our reducer, we need to return another new function, which takes a `C` and an `A`, aka the actual accumulation and element:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (@escaping (C, B) -> C) -> (C, A) -> C {
    return { reducer in // (C, B) -> C
        return { accumulation, element in // C, A
            // ...
        }
    }
}
```

Finally, in this nested function, we need to return a new `C`. How do we return a new `C`? Well, our `reducer` parameter is a function which takes `C`, and `B`, and returns `C`. So using it should work quite nicely. However, the `element` parameter is of type `A`; we can convert it to an element of type `B` by using our `transform` parameter. Nifty, right?

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (@escaping (C, B) -> C) -> (C, A) -> C {
    return { reducer in // (C, B) -> C
        return { accumulation, element in // C, A
            let newElement = transform(element) // B
            return reducer(accumulation, newElement) // C
        }
    }
}
```

And there you go! You‚Äôve successfully created what fancy functional programming people like to call *transducers*. However, that isn‚Äôt a term of art in Swift, so I prefer calling them *higher-order reducers*. Similarly to higher-order functions which take a function and return a new function, *higher-order reducers* take a reducer and return a new reducer.

### 2. Filter

Filtering an element is actually very similar to mapping over one ‚Äî except instead of transforming each element with a function, you instead decide whether with a function whether the element should be reduced into the accumulation or not. That means that we‚Äôll only have two generic types, `A` and `C`, since we won‚Äôt be doing any transformations. We‚Äôll still be taking one parameter, this time a function which takes an `A`, and returns a `Bool`, deciding whether the element should be reduced or not. So already our function signature will look like this:

```swift
func filter<A, C>(_ isIncluded: @escaping (A) -> Bool) -> (@escaping (C, A) -> C) -> (C, A) -> C
```

In English, this reads out as:

‚ÄúFilter is a function which takes a function from A to Bool, and returns a new function. This new function takes a reducer which takes C and A and returns C, and it returns a new reducer which also takes C and A and returns C.‚Äù

Implementing it will feel quite similar to `map`:

```swift
func filter<A, C>(_ isIncluded: @escaping (A) -> Bool) -> (@escaping (C, A) -> C) -> (C, A) -> C {
    return { reducer in // (C, A) -> C
        return { accumulation, element in // C, A
            if isIncluded(element) /* Bool */ {
                return reducer(accumulation, element) // C
            } else {
                return accumulation // C
            }
        }
    }
}
```

And there‚Äôs another *higher-order reducer* you can add to your tool-belt.

### 3. Return the accumulation

So how about returning the accumulation, with / without the element appended to it? Well it turns out we‚Äôve already taken care of that logic in our new higher-order reducers. Think about it, that second parameter in the functions, the one we call ‚Äúreducer‚Äù ‚Äî that‚Äôs the function which would append the element to the accumulation! In the `map` function, we call it on every single transformed element, while in the `filter` function, we only call it if the `isIncluded` function returns true. 

A reducer function who‚Äôs job is to append elements to accumulations and return the accumulation‚Ä¶rings a bell, doesn‚Äôt it? Turns out it‚Äôs the `append` function we defined way up above because we saw it as a reoccurring pattern:

```swift
func append<A, B>(_ element: A, to accumulation: B) -> B where B: RangeReplaceableCollection, B.Element == A {
    return accumulation + [element]
}
```

It seems to me like we have all the chess pieces in place now. We have:

- Higher-order reducers for mapping and filtering, each of which take some function, and then take a reducer
- A reducer used for appending elements to accumulations

Once we give our appending reducer to the higher-order reducer, we‚Äôll get back a new reducer which we can pass right into the `.reduce([], ...)` method! Sounds to me like it‚Äôs time for some composition.

## Composition craze, or function fever

Indeed, composition is the cornerstone of functional programming. It‚Äôs the reason why we made those functions the way we did, so that then they can all fit together like Lego blocks. Before we do anything rash, let‚Äôs remind ourselves of the function signature for the `.reduce` method on sequences:

> `func reduce<Result>(_ initialValue: Result,_ nextPartialResult: (Result, Element) -> Result) -> Result`

What interests us is the second parameter, of type `(Result, Element) -> Result`. I don‚Äôt know about you, but that looks like to reducer to me! And, as we just saw, once we give a higher-order reducer like `map` a mapping function and then a reducer like `append`, we get back a reducer with the exact same shape as `(Result, Element) -> Result`. So we should be able to plug the result right in. Let‚Äôs use our mapping cars to drivers example to try it out. We‚Äôre going head-first into function currying here, so scroll back up to that section if you need a refresher.

Let‚Äôs do this backwards, and think about what we want the end result to be:

```swift
let drivers: [Driver] = cars.reduce([], /* ([Driver], Car) -> [Driver] */)
```

Since `map` is a curried function, we can go step-by-step, giving it one parameter at a time. First off is the transform closure, which in this case transforms a `Car` into a `Driver`. In the beginning, we defined an initializer on `Driver` which takes a `Car`, so we can just use that.

```swift
let carToDriver = map(Driver.init)
```

I wonder, what‚Äôs the type of the `carToDriver` function?

```swift
type(of: carToDriver) // (@escaping ([Driver], Driver) -> [Driver]) -> ([Driver], Car) -> [Driver]
```

This may seem pretty intense, but if you look carefully, you might recognise its shape. It‚Äôs just the return type of `map` function with `A`, `B`, `C ` replaced by `Car`, `Driver`, and  `[Driver]`. 

Let‚Äôs plug in the next parameter. As you see above, it expects a function that does `([Driver], Driver) -> [Driver]`. Looks to me like the perfect opportunity for the `append` function:

```swift
let reducer = carToDriver(append)
type(of: reducer) // ([Driver], Car) -> [Driver]
```

And there we have our reducer! We can now plug that reducer into the `.reduce([], ...)` method:

```swift
let drivers = cars.reduce([], reducer)
```

Let‚Äôs collapse everything we did into one:

```swift
let drivers: [Driver] = cars.reduce([], map(Driver.init)(append))
```

Beautiful, isn‚Äôt it? All we‚Äôve done is compose a few functions together, and now we get the full power of `map`. We can of course do the same thing with filter:

```swift
let reducer = filter(\Driver.isAdventurous)(append) // ([Driver], Driver) -> [Driver]
let adventurousDrivers: [Driver] = drivers.reduce([], reducer)
// or
let adventurousDrivers: [Driver] = drivers.reduce([], filter(\.isAdventurous)(append))
```

Great! We‚Äôve regained the full power of `filter` by once again simply composing a few functions together. 

But wait a minute, I‚Äôm interested in the signature of that first line, where `reducer` is of type `([Driver], Driver) -> [Driver]`. Scroll up a little bit to where we defined the `carToDriver` function using `map`. Doesn‚Äôt `carToDriver` expect a parameter with that exact same type signature?

```swift
type(of: carToDriver) // (@escaping ([Driver], Driver) -> [Driver]) -> ([Driver], Car) -> [Driver]
type(of: filter(\Driver.isAdventurous)(append)) // ([Driver], Driver) -> [Driver]
```

That means even more composition for us. Indeed, we can chain  `map` and `filter` as much we want, since they both want a reducer as a parameter, but also both return a reducer. 

We‚Äôve finally come to the point where we‚Äôve fully regained the power of *declaratively* chaining `map` and `filter` instead of imperative control flow. However, since we‚Äôre in a reduce function, no intermediate arrays between `map` and `filter` will be created!

```swift
let adventurousDrivers: [Driver] = cars
    .map(Driver.init)
	.filter(\.isAdventurous)
// vs
let adventurousDrivers: [Driver] = cars.reduce(
    [],
    map(Driver.init)(filter(\.isAdventurous)(append))
)
```

If you understand what‚Äôs going on, why the `map` and `filter` are chain-able, and why they return a reducer, then you‚Äôve truly understood the shape of functions. You can consider yourself proud.

However, the shape of functions and function currying isn‚Äôt the only thing that matters, is it? This is Swift after all! What about aesthetics?

## Piping down the drain

An attractive feature of method chaining like in the first example of the code snippet above, is how easy it is to read. Left and right, up and down, nicely aligned, not too many parenthesis. A language designer‚Äôs dream. Is there a way to restore some of that readability when using the higher-order reducers?

The main obstacle to readability here is the heavy use of parenthesis. It may not seem to bad now, but once you have five or six `map` and `filter`s chained together, aesthetics go down the drain. Isn‚Äôt it ironic that the solution to this is piping?

What are the components of a function call? There is the name of the function itself, and then there is the parameter given to it, usually surrounded by parenthesis. So, we could simply give these two components separately, and then defer the use of parenthesis to some underlying function. This is the concept behind *backwards piping*. With *backwards piping*, you have the function on the left, an operator (usually `<|`) in the middle, and the argument on the right.

```swift
precedencegroup BackwardPipe {
    associativity: right
}

infix operator <|: BackwardPipe

func <| <A, B>(lhs: (A) -> B, rhs: A) -> B {
    return lhs(rhs)
}
```

For instance, the `cos(_:)` function returns the cosine of any number:

```swift
cos(5) // 0.28366...

cos <| 5 // 0.28366...
```

As you can see, we are *piping* the number 5 into the function `cos` . One might think this doesn‚Äôt make much difference here, but it has a drastic effect when used with the higher-order reducers:

```swift
let adventurousDrivers: [Driver] = cars.reduce([], map(Driver.init) <| filter(\.isAdventurous) <| append)
// or
let adventurousDrivers: [Driver] = cars
	.reduce([], map(Driver.init) <|
            	filter(\.isAdventurous) <|
            	append
           )
```

This looks much cleaner in my opinion, and restores the left-to-right and up-and-down readability that we crave for.

Now, although aesthetics are of course very important to Swift, there is something else which is as important: performance.

## In-and-out

Let‚Äôs think back for a moment to the reason we even started working on these *higher-order reducers*. It was so that we don‚Äôt create intermediate arrays between our `map` and `filter` ‚Äî and that‚Äôs something we‚Äôve accomplished, and accomplished very nicely might I add. However, something even worse is going on: we‚Äôre creating intermediate arrays between **each element**.

Another essential skill to have in addition to understanding the shape of functions, is a more general one: being able to navigate around the [standard library source code](https://github.com/apple/swift/tree/main/stdlib). The standard library lies at the very basis of our own code, but is also a great example of what performant and efficient Swift code looks like. I highly advise anyone who doesn‚Äôt do so regularly to surf around the repo and get familiar with it. 

I digress. What we want to understand is why an intermediate array is created after each iteration. For that, we‚Äôre going into the **public/core/SequenceAlgorithms.swift** and look at the implementation for `reduce(_:_:)`:

```swift
extension Sequence {
  public func reduce<Result>(
    _ initialResult: Result,
    _ nextPartialResult:
      (_ partialResult: Result, Element) -> Result
  ) -> Result {
    var accumulator = initialResult
    for element in self {
      accumulator = nextPartialResult(accumulator, element) // üö®üö®
    }
    return accumulator
  }
}
```

 As you can see, we‚Äôre just looping over all the elements in the sequence, reducing each element into the accumulator thanks to the reducer function named `nextPartialResult`, which of course has the shape `(A, B) -> A`.

However, there‚Äôs one line which is the source of our misfortune:

```swift
accumulator = try nextPartialResult(accumulator, element)
```

Every time we loop over an element, we create a new sequence thanks to the `nextPartialResult` reducer, and then reassign it to the current accumulation. Performance-wise, this isn‚Äôt great. Creating and reassigning arrays can be costly operations, which is the exact opposite of what we want.

Thankfully, the Core Team understands this too, and has thus gifted us with a more efficient and performant alternative:

```swift
extension Sequence {
  public func reduce<Result>(
    into initialResult: __owned Result,
    _ updateAccumulatingResult:
      (_ partialResult: inout Result, Element) -> Void
  ) -> Result {
      var accumulator = initialResult
      for element in self {
        updateAccumulatingResult(&accumulator, element) // ‚úÖ‚úÖ
      }
      return accumulator
    }
  }
}
```

Generally speaking, this implementation is almost identical to the one before. However, there is one big difference: the reducer parameter named `updateAccumulatingResult`. As you can see, its shape is seemingly different, from`(A, B) -> A` to `(inout A, B) -> Void`. But what is *inout* anyways?

In Swift, function parameters are constants, which mean that we can‚Äôt change them, only copy them or pass them around. However, when a parameter is marked with *inout*, you‚Äôre allowed to mutate it *in-place*, and those changes are reflected in the value given buy the caller of the function.

As an example, we can look at our `append` function:

```swift
func append<A, B>(to accumulation: A, element: B) -> A where A: RangeReplaceableCollection, A.Element == B {
    return accumulation + [element]
}

let numbers = [1, 2, 3, 4, 5]
let moreNumbers = append(to: numbers, element: 6)
```

Because we can‚Äôt mutate the `accumulation` in-place, we need to return a new one with the new element appended to it. However, with *inout*, we don‚Äôt need to return a new `accumulation` anymore, we just need to mutate the one given to us. This also means that we return `Void` now.

```swift
func append<A, B>(to accumulation: inout A, element: B) -> Void where A: RangeReplaceableCollection, A.Element == B {
    accumulation.append(element)
}

let numbers = [1, 2, 3, 4, 5]
append(to: &numbers, element: 6)
```

These two functions basically do the same thing ‚Äî they add an element to an array. While the first returns a new array with the element appended to it, the second just appends the element directly. 

Remember, our `append` function is a reducer. So, more generally, we can say that any function of type `(A, B) -> A`, can also be expressed as `(inout A, B) -> Void`.

Ok, so now that we understand what *inout* does, why would this second implementation of `reduce(_:_:)`, called `reduce(into:_:)` be better for our use-case? Well, since the second one uses *inout*, it only ever needs to allocate a single array, since that array is then mutated **in-place** by the reducer parameter as the function loops through each element. Neat, right?

However, we now need to change our higher-order reducers. While the first `reduce(_:_:)` function expects a reducer of type `(A, B) -> A` as its second parameter, our new `reduce(into:_:)` function expects a reducer of type `(inout A, B) -> Void`. Therefore, our higher-order reducers need to be adapted for this. Let‚Äôs remind ourselves what they look like:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (@escaping (C, B) -> C) -> (C, A) -> C {
    return { reducer in
        return { accumulation, element in
            return reducer(accumulation, transform(element))
        }
    }
}

func filter<A, C>(_ isIncluded: @escaping (A) -> Bool) -> (@escaping (C, A) -> C) -> (C, A) -> C {
    return { reducer in
        return { accumulation, element in
            if isIncluded(element) {
                return reducer(accumulation, element)
            } else {
                return accumulation
            }
        }
    }
}
```

As we just saw, a reducer of type `(A, B) -> B` can also be expressed as  `(inout A, B) -> Void`. So, we should just replace the first with the second whenever we see it:

```swift
func map<A, B, C>(_ transform: @escaping (A) -> B) -> (@escaping (inout C, B) -> Void) -> (inout C, A) -> Void {
    return { reducer in
        return { accumulation, element in
            reducer(&accumulation, transform(element))
        }
    }
}

func filter<A, C>(_ isIncluded: @escaping (A) -> Bool) -> (@escaping (inout C, B) -> Void) -> (inout C, A) -> Void {
    return { reducer in
        return { accumulation, element in
            if isIncluded(element) {
                reducer(&accumulation, element)
            }
        }
    }
}
```

Now, using our new definition of `append` of type `(inout A, B) -> Void`, we can do the exact same things as before:

```swift
let adventurousDrivers: [Driver] = cars.reduce(into: [], map(Driver.init) <| filter(\.isAdventurous) <| append)
```

Only now we‚Äôre only ever allocating one array! This is a great boost for performance indeed.

## Finishing thoughts

You‚Äôve made it. Quite long, I know, I know. But look how far we‚Äôve come! We started off with a jumbled mess of mutations which don‚Äôt scale nor compose, and have ended with a single succinct line of code where we *describe* what we want to do with our array.

Nevertheless, these higher-order reducers aren‚Äôt the programming invention of the century, nor are they *essential* to the success of your code. No, the real point of learning about them was the journey.

Throughout this article, you‚Äôve learned to understand that functions don‚Äôt just have some parameters and an implementation ‚Äî they have a *shape*. A shape such as `(A, B) -> A`, or `(A) -> B`, or even a more fancy one like `(inout A, B) -> Void`.

And it‚Äôs through understanding this shape of functions that we can learn to apply and compose functions together, in ways which empower incredibly expressive yet efficient code. Thanks for reading!



